{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TensorOpParams' from 'cumm.gemm.algospec.core' (/home/samuel/.local/lib/python3.10/site-packages/cumm/gemm/algospec/core.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mEHydro_TreeUnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TreeProjectorTrainer\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchsparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m     10\u001b[0m F\u001b[38;5;241m.\u001b[39mset_kmap_mode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhashmap_on_the_fly\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/EHydro_TreeUnet/EHydro_TreeUnet/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TreeProjector, TreeUNet\n",
      "File \u001b[0;32m~/EHydro_TreeUnet/EHydro_TreeUnet/models/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree_projector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TreeProjector\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree_unet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TreeUNet\n",
      "File \u001b[0;32m~/EHydro_TreeUnet/EHydro_TreeUnet/models/tree_projector.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VoxelDecoder, DirHead, MagHead, InstanceHead, CentroidHead\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchsparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn \u001b[38;5;28;01mas\u001b[39;00m spnn\n",
      "File \u001b[0;32m~/EHydro_TreeUnet/EHydro_TreeUnet/modules/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdirection_head\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DirHead\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmagnitude_head\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MagHead\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minstance_head\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InstanceHead\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcentroid_head\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CentroidHead\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FocalLoss\n",
      "File \u001b[0;32m~/EHydro_TreeUnet/EHydro_TreeUnet/modules/instance_head.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchsparse\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspconv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspconv\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspconv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspF\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn, cat\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/spconv/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2021 Yan Yan\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build \u001b[38;5;28;01mas\u001b[39;00m _build\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConvAlgo, AlgoHint\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__version__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/spconv/core.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcumm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgemm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m kernel\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcumm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgemm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgospec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorOpParams\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcumm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_gemm_params \u001b[38;5;28;01mas\u001b[39;00m gen_conv_params, ConvFwdAndBwdInput, ConvBwdWeight, ConvIterAlgo, GemmAlgo\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcumm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (NCHW, NHWC, ConvEnum, ConvIterAlgo, ConvLayout,\n\u001b[1;32m     21\u001b[0m                              ConvLayoutType, ConvMode, ConvOpType)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'TensorOpParams' from 'cumm.gemm.algospec.core' (/home/samuel/.local/lib/python3.10/site-packages/cumm/gemm/algospec/core.py)"
     ]
    }
   ],
   "source": [
    "#import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from EHydro_TreeUnet.trainers import TreeProjectorTrainer\n",
    "from torchsparse.nn import functional as F\n",
    "\n",
    "F.set_kmap_mode(\"hashmap_on_the_fly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING = True\n",
    "\n",
    "DATASET_FOLDER = Path.home() / 'datasets/MixedDataset'\n",
    "WEIGHTS_FILE = 'tree_projector_instance_VS-0.2_DA-48_E-3_v2.pth'\n",
    "CHECKPOINT_FILE = None\n",
    "FEAT_KEYS = ['intensity']\n",
    "IGNORE_CLASS = []\n",
    "CHANNELS = [16, 32, 64, 128]\n",
    "LATENT_DIM = 256\n",
    "INSTANCE_DENSITY = 0.01\n",
    "CENTROID_THRES = 0.1\n",
    "PEAK_RADIUS = 2\n",
    "MIN_SCORE_FOR_CENTROID = 0.0\n",
    "DESCRIPTOR_DIM = 32\n",
    "TRAIN_PCT = 0.9\n",
    "VOXEL_SIZE = 0.2\n",
    "DATA_AUGMENTATION_COEF = 48\n",
    "EPOCHS = 3\n",
    "SEMANTIC_LOSS_COEF = 1.0\n",
    "CENTROID_LOSS_COEF = 1.0\n",
    "INSTANCE_LOSS_COEF = 1.0\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(arr: np.ndarray, window: int) -> np.ndarray:\n",
    "    if window <= 1:\n",
    "        return arr\n",
    "\n",
    "    kernel = np.ones(window, dtype=float)\n",
    "\n",
    "    if arr.ndim == 1:\n",
    "        denom = np.convolve(np.ones_like(arr), kernel, mode=\"same\")\n",
    "        return np.convolve(arr, kernel, mode=\"same\") / denom\n",
    "\n",
    "    # 2-D: suavizar cada columna por separado\n",
    "    smoothed = np.empty_like(arr, dtype=float)\n",
    "    denom = np.convolve(np.ones(arr.shape[0]), kernel, mode=\"same\")\n",
    "    for c in range(arr.shape[1]):\n",
    "        smoothed[:, c] = np.convolve(arr[:, c], kernel, mode=\"same\") / denom\n",
    "    return smoothed\n",
    "        \n",
    "def gen_charts(trainer, losses, stats, training: bool, window: int = 10, ignore_class = []):\n",
    "    keys = stats[0].keys()\n",
    "    stats = {k: np.array([d[k] for d in stats]) for k in keys}\n",
    "\n",
    "    losses_s      = np.clip(smooth(np.asarray(losses), window), 0.0, 10.0)\n",
    "    miou_s        = smooth(stats['miou'], window)\n",
    "    iou_s         = smooth(np.asarray(stats['iou_per_class']), window)\n",
    "    prec_macro_s  = smooth(stats['precision_macro'], window)\n",
    "    prec_s        = smooth(np.asarray(stats['precision_per_class']), window)\n",
    "    recall_macro_s= smooth(stats['recall_macro'], window)\n",
    "    recall_s      = smooth(np.asarray(stats['recall_per_class']), window)\n",
    "    f1_macro_s    = smooth(stats['f1_macro'], window)\n",
    "    f1_s          = smooth(np.asarray(stats['f1_per_class']), window)\n",
    "\n",
    "    # --- 1. Loss -------------------------------------------------------------\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses_s, label=f\"{'Training' if training else 'Inference'} Loss (MA{window})\")\n",
    "    plt.xlabel(\"Step\"); plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"Loss evolution during {'Training' if training else 'Inference'}\")\n",
    "    plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "    # --- 2. mIoU (macro) -----------------------------------------------------\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(miou_s, label=f\"{'Training' if training else 'Inference'} mIoU (MA{window})\")\n",
    "    plt.xlabel(\"Step\"); plt.ylabel(\"mIoU\")\n",
    "    plt.title(f\"mIoU evolution during {'Training' if training else 'Inference'}\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "    # --- 3. IoU per class ----------------------------------------------------\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for c in range(trainer.dataset.num_classes):\n",
    "        if trainer.dataset.class_names[c] in ignore_class:\n",
    "            continue\n",
    "        \n",
    "        plt.plot(iou_s[:, c], label=trainer.dataset.class_names[c])\n",
    "    plt.xlabel(\"Step\"); plt.ylabel(\"IoU\")\n",
    "    plt.title(f\"IoU evolution during {'Training' if training else 'Inference'} (MA{window})\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "    # --- 4. Precision (macro) -----------------------------------------------\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(prec_macro_s, label=f\"{'Training' if training else 'Inference'} precision (MA{window})\")\n",
    "    plt.xlabel(\"Step\"); plt.ylabel(\"Precision\")\n",
    "    plt.title(f\"Precision evolution during {'Training' if training else 'Inference'}\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "    # --- 5. Precision per class ---------------------------------------------\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for c in range(trainer.dataset.num_classes):\n",
    "        if trainer.dataset.class_names[c] in ignore_class:\n",
    "            continue\n",
    "        \n",
    "        plt.plot(prec_s[:, c], label=trainer.dataset.class_names[c])\n",
    "    plt.xlabel(\"Step\"); plt.ylabel(\"Precision\")\n",
    "    plt.title(f\"Precision evolution during {'Training' if training else 'Inference'} (MA{window})\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "    # --- 6. Recall (macro) ---------------------------------------------------\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(recall_macro_s, label=f\"{'Training' if training else 'Inference'} recall (MA{window})\")\n",
    "    plt.xlabel(\"Step\"); plt.ylabel(\"Recall\")\n",
    "    plt.title(f\"Recall evolution during {'Training' if training else 'Inference'}\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "    # --- 7. Recall per class -------------------------------------------------\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for c in range(trainer.dataset.num_classes):\n",
    "        if trainer.dataset.class_names[c] in ignore_class:\n",
    "            continue\n",
    "        \n",
    "        plt.plot(recall_s[:, c], label=trainer.dataset.class_names[c])\n",
    "    plt.xlabel(\"Step\"); plt.ylabel(\"Recall\")\n",
    "    plt.title(f\"Recall evolution during {'Training' if training else 'Inference'} (MA{window})\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "    # --- 8. F1 (macro) -------------------------------------------------------\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(f1_macro_s, label=f\"{'Training' if training else 'Inference'} F1 (MA{window})\")\n",
    "    plt.xlabel(\"Step\"); plt.ylabel(\"F1\")\n",
    "    plt.title(f\"F1 evolution during {'Training' if training else 'Inference'}\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "    # --- 9. F1 per class -----------------------------------------------------\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for c in range(trainer.dataset.num_classes):\n",
    "        if trainer.dataset.class_names[c] in ignore_class:\n",
    "            continue\n",
    "        \n",
    "        plt.plot(f1_s[:, c], label=trainer.dataset.class_names[c])\n",
    "    plt.xlabel(\"Step\"); plt.ylabel(\"F1\")\n",
    "    plt.title(f\"F1 evolution during {'Training' if training else 'Inference'} (MA{window})\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "    column_names = ['IoU', 'Precision', 'Recall', 'F1']\n",
    "    row_names = [trainer.dataset.class_names[c] for c in range(trainer.dataset.num_classes) if trainer.dataset.class_names[c] not in ignore_class]\n",
    "    row_names.append('Mean')\n",
    "\n",
    "    iou_arr = np.asarray(stats['iou_per_class'])\n",
    "    prec_arr = np.asarray(stats['precision_per_class'])\n",
    "    recall_arr = np.asarray(stats['recall_per_class'])\n",
    "    f1_arr = np.asarray(stats['f1_per_class'])\n",
    "\n",
    "    data = [\n",
    "        [iou_arr[:, c].mean(), prec_arr[:, c].mean(), recall_arr[:, c].mean(), f1_arr[:, c].mean()]\n",
    "    for c in range(trainer.dataset.num_classes) if trainer.dataset.class_names[c] not in ignore_class]\n",
    "\n",
    "    means = np.array(data).mean(axis=0)\n",
    "    data.append(list(means))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=column_names, index=row_names)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf32 enabled: False\n",
      "Parámetros totales: 12,794,062\n",
      "Parámetros entrenables: 12,794,062\n",
      "\n",
      "=== Starting epoch 1 ===\n",
      "Training instance correlation with labels instead of predictions by now...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]:   0%|          | 0/3936 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5536) must match the size of tensor b (792) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m\n\u001b[1;32m      1\u001b[0m tester \u001b[38;5;241m=\u001b[39m TreeProjectorTrainer(\n\u001b[1;32m      2\u001b[0m     dataset_folder\u001b[38;5;241m=\u001b[39mDATASET_FOLDER,\n\u001b[1;32m      3\u001b[0m     voxel_size\u001b[38;5;241m=\u001b[39mVOXEL_SIZE,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     checkpoint_file\u001b[38;5;241m=\u001b[39mCHECKPOINT_FILE\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRAINING:\n\u001b[0;32m---> 25\u001b[0m     \u001b[43mtester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     stats \u001b[38;5;241m=\u001b[39m tester\u001b[38;5;241m.\u001b[39mstats\n\u001b[1;32m     27\u001b[0m     losses \u001b[38;5;241m=\u001b[39m tester\u001b[38;5;241m.\u001b[39mlosses\n",
      "File \u001b[0;32m~/EHydro_TreeUnet/EHydro_TreeUnet/trainers/projector_trainer.py:312\u001b[0m, in \u001b[0;36mTreeProjectorTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m amp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 312\u001b[0m         semantic_output, centroid_score_output, centroid_confidence_output, instance_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentroid_score_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m         semantic_output, centroid_score_output, centroid_confidence_output, instance_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model(inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/EHydro_TreeUnet/EHydro_TreeUnet/models/tree_projector.py:46\u001b[0m, in \u001b[0;36mTreeProjector.forward\u001b[0;34m(self, x, centroid_score_labels)\u001b[0m\n\u001b[1;32m     44\u001b[0m     centroid_confidence_output, instance_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance_head(feats, centroid_score_output)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     centroid_confidence_output, instance_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentroid_score_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m semantic_output, centroid_score_output, centroid_confidence_output, instance_output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/EHydro_TreeUnet/EHydro_TreeUnet/modules/instance_head.py:122\u001b[0m, in \u001b[0;36mInstanceHead.forward\u001b[0;34m(self, voxel_feats, centroid_scores)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, voxel_feats, centroid_scores):\n\u001b[0;32m--> 122\u001b[0m     centroid_feats, centroid_confidences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_centroid_peaks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvoxel_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentroid_scores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     voxel_descriptors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoxel_descriptor(voxel_feats)\n\u001b[1;32m    125\u001b[0m     center_descriptors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenter_descriptor(centroid_feats)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/EHydro_TreeUnet/EHydro_TreeUnet/modules/instance_head.py:108\u001b[0m, in \u001b[0;36mInstanceHead._find_centroid_peaks\u001b[0;34m(self, voxel_feats, centroid_confidences)\u001b[0m\n\u001b[1;32m    105\u001b[0m hmax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_pool(centroid_confidences_spconv)\n\u001b[1;32m    106\u001b[0m avg_feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavg_pool(voxel_feats_spconv)\n\u001b[0;32m--> 108\u001b[0m peak_mask \u001b[38;5;241m=\u001b[39m \u001b[43mhmax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcentroid_confidences_spconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\n\u001b[1;32m    110\u001b[0m peak_coords \u001b[38;5;241m=\u001b[39m centroid_confidences_spconv\u001b[38;5;241m.\u001b[39mindices[peak_mask]\n\u001b[1;32m    111\u001b[0m peak_scores \u001b[38;5;241m=\u001b[39m centroid_confidences_spconv\u001b[38;5;241m.\u001b[39mfeatures[peak_mask]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5536) must match the size of tensor b (792) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "tester = TreeProjectorTrainer(\n",
    "    dataset_folder=DATASET_FOLDER,\n",
    "    voxel_size=VOXEL_SIZE,\n",
    "    train_pct=TRAIN_PCT,\n",
    "    data_augmentation_coef=DATA_AUGMENTATION_COEF,\n",
    "    epochs=EPOCHS,\n",
    "    feat_keys=FEAT_KEYS,\n",
    "    channels=CHANNELS,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    instance_density=INSTANCE_DENSITY,\n",
    "    centroid_thres=CENTROID_THRES,\n",
    "    peak_radius=PEAK_RADIUS,\n",
    "    min_score_for_center=MIN_SCORE_FOR_CENTROID,\n",
    "    descriptor_dim=DESCRIPTOR_DIM,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    training=TRAINING,\n",
    "    semantic_loss_coef=SEMANTIC_LOSS_COEF,\n",
    "    centroid_loss_coef=CENTROID_LOSS_COEF,\n",
    "    instance_loss_coef=INSTANCE_LOSS_COEF,\n",
    "    weights_file=WEIGHTS_FILE,\n",
    "    checkpoint_file=CHECKPOINT_FILE\n",
    ")\n",
    "\n",
    "if TRAINING:\n",
    "    tester.train()\n",
    "    stats = tester.stats\n",
    "    losses = tester.losses\n",
    "    gen_charts(tester, losses, stats, True, ignore_class=IGNORE_CLASS)\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd2 = o3d.geometry.PointCloud()\n",
    "for voxels, semantic_output, semantic_labels, centroid_score_output, centroid_score_labels, instance_output, instance_labels, centroid_voxels, centroid_confidence_output in tester.eval():\n",
    "    batch_idx = voxels[:, 0]\n",
    "    centroid_batch_idx = centroid_voxels[:, 0]\n",
    "    voxels = voxels[:, 1:]\n",
    "    centroid_voxels = centroid_voxels[:, 1:]\n",
    "\n",
    "    for idx in np.unique(batch_idx):\n",
    "        mask = batch_idx == idx\n",
    "        cloud_voxels = voxels[mask]\n",
    "        cloud_semantic_output = semantic_output[mask]\n",
    "        cloud_semantic_labels = semantic_labels[mask]\n",
    "        cloud_centroid_score_output = centroid_score_output[mask]\n",
    "        cloud_centroid_score_labels = centroid_score_labels[mask]\n",
    "        cloud_instance_output = instance_output[mask]\n",
    "        cloud_instance_labels = instance_labels[mask]\n",
    "\n",
    "        mask = centroid_batch_idx == idx\n",
    "        cloud_centroid_voxels = centroid_voxels[mask]\n",
    "        cloud_centroid_confidence_output = centroid_confidence_output[mask]\n",
    "\n",
    "        pcd.points = o3d.utility.Vector3dVector(cloud_voxels)\n",
    "\n",
    "        colors = tester.dataset.class_colormap[cloud_semantic_labels] / 255.0\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "        colors = tester.dataset.class_colormap[cloud_semantic_output] / 255.0\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "        cmap = plt.get_cmap('viridis')\n",
    "\n",
    "        colors = cmap(cloud_centroid_score_labels[:, 0])[:, :3]\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "        colors = cmap(cloud_centroid_score_output[:, 0])[:, :3]\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "        spheres = []\n",
    "        colors = tester.dataset.class_colormap[cloud_semantic_labels] / 255.0\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        for i in range(cloud_centroid_voxels.shape[0]):\n",
    "            center = cloud_centroid_voxels[i]\n",
    "            confidence = cloud_centroid_confidence_output[i][0]\n",
    "\n",
    "            sphere = o3d.geometry.TriangleMesh.create_sphere(radius=1.5)\n",
    "            sphere.translate(center)\n",
    "            color = cmap(confidence)[:3]\n",
    "            sphere.paint_uniform_color(color)\n",
    "            spheres.append(sphere)\n",
    "\n",
    "        o3d.visualization.draw_geometries([pcd] + spheres)\n",
    "\n",
    "        unique_ids = np.unique(cloud_instance_labels)\n",
    "        rng = np.random.default_rng(0)\n",
    "        palette = rng.random((len(unique_ids), 3))\n",
    "\n",
    "        id2color = {uid: palette[i] for i, uid in enumerate(unique_ids)}\n",
    "        colors = np.array([id2color[i] for i in cloud_instance_labels], dtype=np.float64)\n",
    "\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "        unique_ids = np.unique(cloud_instance_output)\n",
    "        rng = np.random.default_rng(0)\n",
    "        palette = rng.random((len(unique_ids), 3))\n",
    "\n",
    "        id2color = {uid: palette[i] for i, uid in enumerate(unique_ids)}\n",
    "        colors = np.array([id2color[i] for i in cloud_instance_output], dtype=np.float64)\n",
    "\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "gen_charts(tester, tester.losses, tester.stats, False, ignore_class=IGNORE_CLASS)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
