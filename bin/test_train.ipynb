{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"XDG_SESSION_TYPE\"] = \"x11\"\n",
    "os.environ.pop(\"WAYLAND_DISPLAY\", None)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from EHydro_TreeUnet.trainers import TreeProjectorTrainer\n",
    "from torchsparse.nn import functional as F\n",
    "\n",
    "F.set_kmap_mode(\"hashmap_on_the_fly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "TREE_PROJECTOR_DIR = Path(os.environ.get('TREE_PROJECTOR_DIR', Path.home() / 'tree_projector'))\n",
    "DATASET_FOLDER = 'MixedDataset'\n",
    "VERSION_NAME = 'tree_projector_VS-0.2_DA-48_E-3_V5'\n",
    "\n",
    "VOXEL_SIZE = 0.3\n",
    "FEAT_KEYS = ['intensity']\n",
    "CENTROID_SIGMA_MIN = 1.0\n",
    "CENTROID_SIGMA_MAX = 4.0\n",
    "CENTROID_SIGMA_DIVISOR = 18.0\n",
    "TRAIN_PCT = 0.9\n",
    "DATA_AUGMENTATION_COEF = 48\n",
    "YAW_RANGE = (0.0, 360.0)\n",
    "TILT_RANGE = (-5.0, 5.0)\n",
    "SCALE_RANGE = (0.9, 1.3)\n",
    "\n",
    "TRAINING = False\n",
    "TEST_LR = []\n",
    "EPOCHS = 5\n",
    "START_ON_EPOCH = 0\n",
    "BATCH_SIZE = 8\n",
    "SEMANTIC_LOSS_COEF = 2.0\n",
    "CENTROID_LOSS_COEF = 1.0\n",
    "OFFSET_LOSS_COEF = 1.0\n",
    "INSTANCE_LOSS_COEF = 1.0\n",
    "BACKBONE_LR = 2e-3\n",
    "SEMANTIC_LR = 1e-3\n",
    "OFFSET_LR = 2e-2\n",
    "CENTROID_LR = 1e-3\n",
    "INSTANCE_LR = 2e-2\n",
    "WEIGHT_DECAY = 0.04\n",
    "\n",
    "RESNET_BLOCKS = [\n",
    "    (3, 16, 3, 1),\n",
    "    (3, 32, 3, 2),\n",
    "    (3, 64, 3, 2),\n",
    "    (3, 128, 3, 2),\n",
    "    (1, 128, (1, 1, 3), (1, 1, 2)),\n",
    "]\n",
    "INSTANCE_DENSITY = 0.005\n",
    "MIN_TREE_VOLUME = 5.0\n",
    "SCORE_THRES = 0.2\n",
    "CENTROID_THRES = 0.3\n",
    "MAX_TREES_PER_SCENE = 64\n",
    "DESCRIPTOR_DIM = 16\n",
    "\n",
    "CHARTS_IGNORE_CLASS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros totales: 16,001,308\n",
      "Parámetros entrenables: 16,001,308\n",
      "Resnet generates features at the following scales:\n",
      "\t* (0.3, 0.3, 0.3) meters -> 16 feats.\n",
      "\t* (0.6, 0.6, 0.6) meters -> 32 feats.\n",
      "\t* (1.2, 1.2, 1.2) meters -> 64 feats.\n",
      "\t* (2.4, 2.4, 2.4) meters -> 128 feats.\n",
      "\t* (2.4, 2.4, 4.8) meters -> 128 feats.\n",
      "\n",
      "Minimum scene size: (7.2, 7.2, 14.4) meters\n",
      "[Val]:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "[Val]:   0%|          | 0/2 [00:00<?, ?it/s, VRAM=7.29 GB, Matched=78 / 68, TP=25 / 68, Total=9.0213 →, Semantic=0.3448 →, Centroid=2.9624 →, Offset=3.8518 →, Instance=1.8623 →]\n",
      "[Val]:  50%|█████     | 1/2 [02:39<02:39, 159.77s/it, VRAM=7.29 GB, Matched=78 / 68, TP=25 / 68, Total=9.0213 →, Semantic=0.3448 →, Centroid=2.9624 →, Offset=3.8518 →, Instance=1.8623 →]\n",
      "[Val]:  50%|█████     | 1/2 [02:40<02:39, 159.77s/it, VRAM=7.29 GB, Matched=55 / 49, TP=25 / 49, Total=8.8173 ↓, Semantic=0.3880 ↑, Centroid=2.3153 ↓, Offset=4.6326 ↑, Instance=1.4814 ↓]\n",
      "[Val]: 100%|██████████| 2/2 [03:24<00:00, 92.31s/it, VRAM=7.29 GB, Matched=55 / 49, TP=25 / 49, Total=8.8173 ↓, Semantic=0.3880 ↑, Centroid=2.3153 ↓, Offset=4.6326 ↑, Instance=1.4814 ↓]\n",
      "[Val]: 100%|██████████| 2/2 [03:24<00:00, 102.43s/it, VRAM=7.29 GB, Matched=55 / 49, TP=25 / 49, Total=8.8173 ↓, Semantic=0.3880 ↑, Centroid=2.3153 ↓, Offset=4.6326 ↑, Instance=1.4814 ↓]\n",
      ", VRAM=7.29 GB, Matched=55 / 49, TP=25 / 49, Total=8.8173 ↓, Semantic=0.3880 ↑, Centroid=2.3153 ↓, Offset=4.6326 ↑, Instance=1.4814 ↓\n"
     ]
    }
   ],
   "source": [
    "trainer = TreeProjectorTrainer(\n",
    "    tree_projector_dir=TREE_PROJECTOR_DIR,\n",
    "    dataset_folder=DATASET_FOLDER,\n",
    "    version_name=VERSION_NAME,\n",
    "\n",
    "    voxel_size=VOXEL_SIZE,\n",
    "    feat_keys=FEAT_KEYS,\n",
    "    centroid_sigma_min=CENTROID_SIGMA_MIN,\n",
    "    centroid_sigma_max=CENTROID_SIGMA_MAX,\n",
    "    centroid_sigma_divisor=CENTROID_SIGMA_DIVISOR,\n",
    "    train_pct=TRAIN_PCT,\n",
    "    data_augmentation_coef=DATA_AUGMENTATION_COEF,\n",
    "    yaw_range=YAW_RANGE,\n",
    "    tilt_range=TILT_RANGE,\n",
    "    scale_range=SCALE_RANGE,\n",
    "\n",
    "    training=TRAINING,\n",
    "    test_lr=TEST_LR,\n",
    "    epochs=EPOCHS,\n",
    "    start_on_epoch=START_ON_EPOCH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    semantic_loss_coef=SEMANTIC_LOSS_COEF,\n",
    "    centroid_loss_coef=CENTROID_LOSS_COEF,\n",
    "    offset_loss_coef=OFFSET_LOSS_COEF,\n",
    "    instance_loss_coef=INSTANCE_LOSS_COEF,\n",
    "    backbone_lr=BACKBONE_LR,\n",
    "    semantic_lr=SEMANTIC_LR,\n",
    "    offset_lr=OFFSET_LR,\n",
    "    centroid_lr=CENTROID_LR,\n",
    "    instance_lr=INSTANCE_LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "\n",
    "    resnet_blocks=RESNET_BLOCKS,\n",
    "    instance_density=INSTANCE_DENSITY,\n",
    "    score_thres=SCORE_THRES,\n",
    "    centroid_thres=CENTROID_THRES,\n",
    "    max_trees_per_scene=MAX_TREES_PER_SCENE,\n",
    "    descriptor_dim=DESCRIPTOR_DIM\n",
    ")\n",
    "\n",
    "if TRAINING:\n",
    "    trainer.train()\n",
    "\n",
    "\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pcd_gt = o3d.geometry.PointCloud()\n",
    "pcd_pred = o3d.geometry.PointCloud()\n",
    "\n",
    "for eval_result in trainer.eval():\n",
    "    batch_idx = eval_result['semantic_output'].C.cpu().numpy()[:, 0]\n",
    "    centroid_batch_idx = eval_result['centroid_confidence_output'].C.cpu().numpy()[:, 0]\n",
    "\n",
    "    voxels = eval_result['semantic_output'].C.cpu().numpy()[:, 1:]\n",
    "    centroid_voxels = eval_result['centroid_confidence_output'].C.cpu().numpy()[:, 1:]\n",
    "\n",
    "    semantic_output = torch.argmax(eval_result['semantic_output'].F.cpu(), dim=1).numpy()\n",
    "    semantic_labels = eval_result['semantic_labels'].F.cpu().numpy()\n",
    "\n",
    "    semantic_mask = semantic_labels != 0\n",
    "    centroid_score_output = np.zeros((voxels.shape[0], 1), dtype=float)\n",
    "    centroid_score_output[semantic_mask] = eval_result['centroid_score_output'].F.cpu().numpy()\n",
    "    centroid_score_labels = np.zeros((voxels.shape[0], 1), dtype=float)\n",
    "    centroid_score_labels[semantic_mask] = eval_result['centroid_score_labels'].F.cpu().numpy()\n",
    "\n",
    "    centroid_confidence_output = eval_result['centroid_confidence_output'].F.cpu().numpy()\n",
    "\n",
    "    offset_output = np.zeros((voxels.shape[0], 3), dtype=float)\n",
    "    offset_output[semantic_mask] = eval_result['offset_output'].F.cpu().numpy()\n",
    "    offset_labels = np.zeros((voxels.shape[0], 3), dtype=float)\n",
    "    offset_labels[semantic_mask] = eval_result['offset_labels'].F.cpu().numpy()\n",
    "\n",
    "    instance_output_tmp = torch.argmax(eval_result['instance_output'].F.cpu(), dim=1).numpy()\n",
    "    instance_output = np.full(voxels.shape[0], fill_value=-1, dtype=int)\n",
    "    instance_output[semantic_mask] = instance_output_tmp\n",
    "\n",
    "    gt_indices = eval_result['remap_info']['gt_indices'].cpu().numpy()\n",
    "    pred_indices = eval_result['remap_info']['pred_indices'].cpu().numpy()\n",
    "    num_instances = eval_result['remap_info']['num_instances']\n",
    "\n",
    "    lut = np.full(num_instances, fill_value=-1, dtype=int)\n",
    "    lut[gt_indices] = pred_indices\n",
    "\n",
    "    start = pred_indices.max() + 1 if pred_indices.size else 0\n",
    "    unmatched = np.setdiff1d(np.arange(num_instances), gt_indices)\n",
    "    lut[unmatched] = np.arange(start, start + unmatched.size)\n",
    "    instance_labels_tmp = lut[eval_result['instance_labels'].F.cpu().numpy()]\n",
    "\n",
    "    instance_labels = np.full(voxels.shape[0], fill_value=-1, dtype=int)\n",
    "    instance_labels[semantic_mask] = instance_labels_tmp\n",
    "\n",
    "    rng = np.random.default_rng(0)\n",
    "    palette = []\n",
    "    reserved_colors = np.array([\n",
    "        [0.2, 0.2, 0.2],  # Ground\n",
    "        [1.0, 0.0, 0.0],  # Not matched\n",
    "    ])\n",
    "\n",
    "    while len(palette) < len(np.unique(instance_labels)):\n",
    "        color = rng.random(3)\n",
    "        if np.all(np.linalg.norm(reserved_colors - color, axis=1) > 0.2):\n",
    "            palette.append(color)\n",
    "\n",
    "    palette = np.array(palette)\n",
    "\n",
    "    id2color = {uid: palette[i] for i, uid in enumerate(np.unique(instance_labels)) if i != -1}\n",
    "    diff = np.setdiff1d(np.unique(instance_output), np.unique(instance_labels))\n",
    "    id2color.update({uid: tuple(reserved_colors[1]) for uid in diff})\n",
    "    id2color[-1] = tuple(reserved_colors[0])\n",
    "\n",
    "    for idx in np.unique(batch_idx):\n",
    "        mask = batch_idx == idx\n",
    "        cloud_voxels = voxels[mask]\n",
    "\n",
    "        cloud_semantic_output = semantic_output[mask]\n",
    "        cloud_semantic_labels = semantic_labels[mask]\n",
    "\n",
    "        cloud_centroid_score_output = centroid_score_output[mask]\n",
    "        cloud_centroid_score_labels = centroid_score_labels[mask]\n",
    "\n",
    "        cloud_offset_output = offset_output[mask]\n",
    "        cloud_offset_labels = offset_labels[mask]\n",
    "\n",
    "        cloud_instance_output = instance_output[mask]\n",
    "        cloud_instance_labels = instance_labels[mask]\n",
    "\n",
    "        mask = centroid_batch_idx == idx\n",
    "        cloud_centroid_voxels = centroid_voxels[mask]\n",
    "        cloud_centroid_confidence_output = centroid_confidence_output[mask]\n",
    "\n",
    "        pcd_gt.points = o3d.utility.Vector3dVector(cloud_voxels)\n",
    "        pcd_gt.translate((20 / VOXEL_SIZE, 0, 0))\n",
    "        pcd_pred.points = o3d.utility.Vector3dVector(cloud_voxels)\n",
    "\n",
    "        colors = trainer.dataset.class_colormap[cloud_semantic_labels] / 255.0\n",
    "        pcd_gt.colors = o3d.utility.Vector3dVector(colors)\n",
    "        colors = trainer.dataset.class_colormap[cloud_semantic_output] / 255.0\n",
    "        pcd_pred.colors = o3d.utility.Vector3dVector(colors)\n",
    "        o3d.visualization.draw_geometries([pcd_pred, pcd_gt])\n",
    "\n",
    "        cmap = plt.get_cmap('viridis')\n",
    "        cmap_spheres = plt.get_cmap('inferno')\n",
    "        colors = cmap(cloud_centroid_score_labels[:, 0])[:, :3]\n",
    "        pcd_gt.colors = o3d.utility.Vector3dVector(colors)\n",
    "        colors = cmap(cloud_centroid_score_output[:, 0])[:, :3]\n",
    "        pcd_pred.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "        spheres = []\n",
    "        for i in np.unique(cloud_instance_output):\n",
    "            if i < 0:\n",
    "                continue\n",
    "            \n",
    "            center = centroid_voxels[i]\n",
    "            confidence = centroid_confidence_output[i][0]\n",
    "\n",
    "            sphere = o3d.geometry.TriangleMesh.create_sphere(radius=1.5)\n",
    "            sphere.translate(center)\n",
    "            color = cmap_spheres(confidence)[:3]\n",
    "            sphere.paint_uniform_color(color)\n",
    "            spheres.append(sphere)\n",
    "\n",
    "        o3d.visualization.draw_geometries([pcd_pred, pcd_gt] + spheres)\n",
    "\n",
    "        voxels_disp_output = cloud_voxels + cloud_offset_output\n",
    "        voxels_disp_labels = cloud_voxels + cloud_offset_labels\n",
    "\n",
    "        pcd_gt.points = o3d.utility.Vector3dVector(voxels_disp_labels)\n",
    "        pcd_gt.translate((20 / VOXEL_SIZE, 0, 0))\n",
    "        pcd_pred.points = o3d.utility.Vector3dVector(voxels_disp_output)\n",
    "\n",
    "        colors = trainer.dataset.class_colormap[cloud_semantic_labels] / 255.0\n",
    "        pcd_gt.colors = o3d.utility.Vector3dVector(colors)\n",
    "        colors = trainer.dataset.class_colormap[cloud_semantic_output] / 255.0\n",
    "        pcd_pred.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "        o3d.visualization.draw_geometries([pcd_pred, pcd_gt] + spheres)\n",
    "\n",
    "        pcd_gt.points = o3d.utility.Vector3dVector(cloud_voxels)\n",
    "        pcd_gt.translate((20 / VOXEL_SIZE, 0, 0))\n",
    "        pcd_pred.points = o3d.utility.Vector3dVector(cloud_voxels)\n",
    "\n",
    "        colors = np.array([id2color[i] for i in cloud_instance_labels], dtype=np.float64)\n",
    "        pcd_gt.colors = o3d.utility.Vector3dVector(colors)\n",
    "        colors = np.array([id2color[i] for i in cloud_instance_output], dtype=np.float64)\n",
    "        pcd_pred.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "        o3d.visualization.draw_geometries([pcd_pred, pcd_gt] + spheres)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
