{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff646079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import open3d as o3d\n",
    "import torch\n",
    "import laspy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from laspy import LasData\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from torch.cuda import amp\n",
    "from torchsparse.utils.quantize import sparse_quantize\n",
    "from torchsparse import SparseTensor\n",
    "\n",
    "from EHydro_TreeUnet import TreeProjector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31ceba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "TREE_PROJECTOR_DIR = Path(os.environ.get('TREE_PROJECTOR_DIR', Path.home() / 'tree_projector'))\n",
    "VERSION_NAME = 'tree_projector_VS-0.2_DA-48_E-3_V2'\n",
    "SAVE_CHUNKS = True\n",
    "USE_STORED = True\n",
    "SAVE_SEGMENTED = True\n",
    "SAVE_ALL_SEGMENTS = True\n",
    "CHUNK_SIZE = 12.5\n",
    "MIN_POINTS_PER_PC = 0\n",
    "\n",
    "VOXEL_SIZE = 0.2\n",
    "RESNET_BLOCKS = [\n",
    "    (3, 16, 3, 1),\n",
    "    (3, 32, 3, 2),\n",
    "    (3, 64, 3, 2),\n",
    "    (3, 128, 3, 2),\n",
    "    (1, 128, (1, 1, 3), (1, 1, 2)),\n",
    "]\n",
    "LATENT_DIM = 512\n",
    "INSTANCE_DENSITY = 0.01\n",
    "SCORE_THRES = 0.1\n",
    "CENTROID_THRES = 0.1\n",
    "DESCRIPTOR_DIM = 64\n",
    "\n",
    "# class_names = ['Terrain', 'Low Vegetation', 'Stem', 'Canopy']\n",
    "class_names = ['Terrain', 'Stem', 'Canopy']\n",
    "class_colormap = np.array([\n",
    "    [128, 128, 128], # clase 0 - Terrain - gris\n",
    "    # [147, 255, 138], # clase 1 - Low vegetation - verde claro\n",
    "    [255, 165, 0],   # clase 2 - Stem - naranja\n",
    "    [0, 128, 0],     # clase 3 - Canopy - verde oscuro\n",
    "], dtype=np.uint8)\n",
    "\n",
    "weights_folder = TREE_PROJECTOR_DIR / 'weights' / VERSION_NAME\n",
    "process_folder = TREE_PROJECTOR_DIR / 'to_process'\n",
    "process_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "input_folder = process_folder / 'input'\n",
    "output_folder = process_folder / 'output'\n",
    "segmented_folder = process_folder / 'segmented'\n",
    "segmented_by_folder = process_folder / 'segmented/by_folders'\n",
    "\n",
    "input_folder.mkdir(parents=True, exist_ok=True)\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "segmented_folder.mkdir(parents=True, exist_ok=True)\n",
    "segmented_by_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a886308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkerize(file: LasData, ext: str):\n",
    "    points = file.points\n",
    "    coords = np.vstack((file.x, file.y)).transpose()\n",
    "\n",
    "    idx  = np.floor_divide(coords, CHUNK_SIZE).astype(int)\n",
    "    idx -= idx.min(axis=0)\n",
    "\n",
    "    idx = np.ravel_multi_index(idx.T, idx.max(axis=0) + 1)\n",
    "    chunks = []\n",
    "    for i, unique_idx in enumerate(tqdm(np.unique(idx))):\n",
    "        chunk_points = points[idx == unique_idx]\n",
    "        if len(chunk_points) < MIN_POINTS_PER_PC:\n",
    "            continue\n",
    "\n",
    "        chunk_file = laspy.LasData(file.header)\n",
    "        chunk_file.points = chunk_points\n",
    "        chunks.append(chunk_file)\n",
    "        \n",
    "        if SAVE_CHUNKS:\n",
    "            chunk_file.write(output_folder / f'plot_{i}{ext}')\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9363e02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:29<00:00,  3.63it/s]\n"
     ]
    }
   ],
   "source": [
    "extensions = ('.laz', '.las')\n",
    "point_clouds = sorted(\n",
    "            [f for f in input_folder.rglob(\"*\") if f.is_file() and f.suffix.lower() in extensions],\n",
    "            key=lambda f: f.name\n",
    "        )\n",
    "\n",
    "model = TreeProjector(\n",
    "    in_channels=1,\n",
    "    num_classes=len(class_names),\n",
    "    resnet_blocks=RESNET_BLOCKS,\n",
    "    instance_density=INSTANCE_DENSITY,\n",
    "    score_thres=SCORE_THRES,\n",
    "    centroid_thres=CENTROID_THRES,\n",
    "    descriptor_dim=DESCRIPTOR_DIM\n",
    ")\n",
    "model.load_state_dict(torch.load(weights_folder / f'{VERSION_NAME}_weights.pth'))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "for point_cloud in point_clouds:\n",
    "    if USE_STORED:\n",
    "        chunks = [laspy.read(f) for f in output_folder.rglob(\"*\") if f.is_file() and f.suffix.lower() in extensions]\n",
    "    else:\n",
    "        chunks = chunkerize(laspy.read(point_cloud), point_cloud.suffix.lower())\n",
    "\n",
    "    segmented_chunks = []\n",
    "\n",
    "    instance_offset = 1\n",
    "    for i, chunk in enumerate(tqdm(chunks)):\n",
    "        coords = np.vstack((chunk.x, chunk.y, chunk.z)).transpose()\n",
    "        min_coords = coords.min(axis=0)\n",
    "        coords -= min_coords\n",
    "\n",
    "        intensity = np.array(chunk.intensity)[:, None]\n",
    "        min_intensity = np.min(intensity)\n",
    "        max_intensity = np.max(intensity)\n",
    "        i_norm = (intensity - min_intensity) / (max_intensity - min_intensity)\n",
    "\n",
    "        voxels, indices, inverse_map = sparse_quantize(coords, VOXEL_SIZE, return_index=True, return_inverse=True)\n",
    "\n",
    "        voxels = torch.tensor(voxels, dtype=torch.int).to(device)\n",
    "        batch_index = torch.zeros((voxels.shape[0], 1), dtype=torch.int, device=voxels.device)\n",
    "        voxels = torch.cat([batch_index, voxels], dim=1)\n",
    "        feat = torch.tensor(i_norm.astype(np.float32), dtype=torch.float).to(device)\n",
    "\n",
    "        inputs = SparseTensor(coords=voxels, feats=feat)\n",
    "        with amp.autocast(enabled=True):\n",
    "            semantic_output, instance_output = model(inputs)\n",
    "\n",
    "        voxels = semantic_output.C.cpu().numpy()\n",
    "        semantic_output = torch.argmax(semantic_output.F.cpu(), dim=1).numpy()\n",
    "        instance_output = torch.argmax(instance_output.F.cpu(), dim=1).numpy()\n",
    "        instance_output_full = torch.zeros_like(semantic_output)\n",
    "        max_label = instance_output.max()\n",
    "        instance_output_full[semantic_output != 0] = instance_output + instance_offset\n",
    "        instance_offset += max_label + 1\n",
    "\n",
    "        semantic_output = semantic_output[inverse_map]\n",
    "        instance_output = instance_output_full[inverse_map]\n",
    "\n",
    "        out_file = laspy.LasData(header=chunk.header, points=chunk.points.copy())\n",
    "        out_file.add_extra_dims([laspy.ExtraBytesParams(name=\"semantic_pred\", type=np.int16), laspy.ExtraBytesParams(name=\"instance_pred\", type=np.int32)])\n",
    "        out_file.semantic_pred = semantic_output\n",
    "        out_file.instance_pred = instance_output\n",
    "\n",
    "        segmented_chunks.append(out_file)\n",
    "        if SAVE_ALL_SEGMENTS:\n",
    "            out_file.write(segmented_by_folder / f'plot_{i}.las')\n",
    "\n",
    "    with laspy.open(segmented_folder / 'combined.las', mode='w', header=chunks[0].header) as file:\n",
    "        for chunk in segmented_chunks:\n",
    "            file.write_points(chunk.points)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
