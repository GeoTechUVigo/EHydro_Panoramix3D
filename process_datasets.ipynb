{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc242f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import laspy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54350d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_folder = Path.home() / 'tree_projector/datasets'\n",
    "\n",
    "for_instance_folder = (datasets_folder / 'FORinstance_dataset', datasets_folder / 'MixedDataset')\n",
    "nibio_mls_folder = (datasets_folder / 'NIBIO_MLS', datasets_folder / 'MixedDataset')\n",
    "ehydro_folder = (datasets_folder / 'EHydro_raw', datasets_folder / 'EHydro', datasets_folder / 'EHydro_full')\n",
    "\n",
    "for_instance_folder[0].mkdir(parents=True, exist_ok=True)\n",
    "for_instance_folder[1].mkdir(parents=True, exist_ok=True)\n",
    "nibio_mls_folder[0].mkdir(parents=True, exist_ok=True)\n",
    "nibio_mls_folder[1].mkdir(parents=True, exist_ok=True)\n",
    "ehydro_folder[0].mkdir(parents=True, exist_ok=True)\n",
    "ehydro_folder[1].mkdir(parents=True, exist_ok=True)\n",
    "ehydro_folder[2].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mixed_classes = {\n",
    "    'terrain': 0,\n",
    "    # 'low_vegetation': 1,\n",
    "    'stem': 1,\n",
    "    'canopy': 2\n",
    "}\n",
    "\n",
    "ehydro_classes = {\n",
    "    'terrain': 0,\n",
    "    'low_vegetation': 1,\n",
    "    'tree': 2,\n",
    "    'others': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "918b4efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_point_clouds(folder):\n",
    "    files = sorted(\n",
    "        [f for f in folder.rglob(\"*\") if f.is_file() and f.suffix.lower() in ('.laz', '.las')],\n",
    "        key=lambda f: f.name\n",
    "    )\n",
    "\n",
    "    for path in files:\n",
    "        ext = path.suffix.lower()\n",
    "        file = laspy.read(path)\n",
    "\n",
    "        min_coords = np.array([file.x.min(), file.y.min(), file.z.min()], dtype=np.int64)\n",
    "        mins_world = min_coords * file.header.scales + file.header.offsets\n",
    "        file.header.offsets -= mins_world\n",
    "\n",
    "        intensity = np.array(file.intensity)\n",
    "        min_intensity = np.min(intensity)\n",
    "        max_intensity = np.max(intensity)\n",
    "\n",
    "        file.add_extra_dims([\n",
    "            laspy.ExtraBytesParams(name=\"norm_intensity\", type=np.float32),\n",
    "            laspy.ExtraBytesParams(name=\"semantic_pred\", type=np.int16),\n",
    "            laspy.ExtraBytesParams(name=\"instance_pred\", type=np.int16)\n",
    "        ])\n",
    "\n",
    "        file.norm_intensity = (intensity - min_intensity) / (max_intensity - min_intensity)\n",
    "        yield ext, file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2b243e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [01:13,  2.61s/it]\n"
     ]
    }
   ],
   "source": [
    "for_instance_classes = {\n",
    "    'unclassified': 0,\n",
    "    'low_vegetation': 1,\n",
    "    'terrain': 2,\n",
    "    'out_points': 3,\n",
    "    'stem': 4,\n",
    "    'live_branches': 5,\n",
    "    'woody_branches': 6\n",
    "}\n",
    "\n",
    "for i, (ext, file) in enumerate(tqdm(load_point_clouds(for_instance_folder[0]))):\n",
    "    mask = (file.classification != for_instance_classes['out_points']) & (file.classification != for_instance_classes['unclassified'])  # Eliminamos puntos no clasificados o inválidos\n",
    "    file.points = file.points[mask]\n",
    "\n",
    "    semantic_labels = np.array(file.classification)\n",
    "    remap = np.copy(semantic_labels)\n",
    "\n",
    "    remap = np.where(semantic_labels == for_instance_classes['low_vegetation'], mixed_classes['terrain'], remap)\n",
    "    remap = np.where(semantic_labels == for_instance_classes['terrain'], mixed_classes['terrain'], remap)\n",
    "    remap = np.where(semantic_labels == for_instance_classes['stem'], mixed_classes['stem'], remap)\n",
    "    remap = np.where(semantic_labels == for_instance_classes['live_branches'], mixed_classes['canopy'], remap)\n",
    "    remap = np.where(semantic_labels == for_instance_classes['woody_branches'], mixed_classes['canopy'], remap)\n",
    "\n",
    "    file.semantic_pred = remap\n",
    "    file.instance_pred = file.treeID\n",
    "    file.write(for_instance_folder[1] / f'plot_FORinstance_{i}{ext}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f2421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [01:17,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "nibio_mls_classes = {\n",
    "    'ground': 1,\n",
    "    'vegetation': 2,\n",
    "    'lying_deadwood': 3,\n",
    "    'stems': 4\n",
    "}\n",
    "\n",
    "for i, (ext, file) in enumerate(tqdm(load_point_clouds(nibio_mls_folder[0]))):\n",
    "    semantic_labels = np.array(file.label)\n",
    "    remap = np.copy(semantic_labels)\n",
    "\n",
    "    remap = np.where(semantic_labels == nibio_mls_classes['ground'], mixed_classes['terrain'], remap)\n",
    "    remap = np.where((semantic_labels == nibio_mls_classes['vegetation']) & (file.treeID == 0), mixed_classes['terrain'], remap)\n",
    "    remap = np.where((semantic_labels == nibio_mls_classes['vegetation']) & (file.treeID != 0), mixed_classes['canopy'], remap)\n",
    "    remap = np.where(semantic_labels == 3, mixed_classes['terrain'], remap)\n",
    "    remap = np.where(semantic_labels == 4, mixed_classes['stem'], remap)\n",
    "\n",
    "    file.semantic_pred = remap\n",
    "    file.instance_pred = file.treeID\n",
    "    file.write(nibio_mls_folder[1] / f'plot_NIBIO_MLS_{i}{ext}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1eeb3c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [04:15, 31.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks a priori: 1120\n",
      "Chunks completos, con al menos un 80% del tamaño requerido: 1021 (91.16%)\n",
      "Chunks válidos, con al menos tres instancias y tres clases presentes: 615 (54.91%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a_priori_chunks = 0\n",
    "complete_chunks = 0\n",
    "valid_chunks = 0\n",
    "\n",
    "for i, (ext, file) in enumerate(tqdm(load_point_clouds(ehydro_folder[0]))):\n",
    "    semantic_labels = np.array(file.classification)\n",
    "    remap = np.full_like(semantic_labels, ehydro_classes['others'])\n",
    "    instance_labels = np.array(file.PredInstance)\n",
    "    \n",
    "    ids = np.unique(instance_labels)\n",
    "    ids = ids[ids != 0]\n",
    "\n",
    "    remap = np.where(instance_labels == 0, ehydro_classes['terrain'], remap)\n",
    "    for id in ids:\n",
    "        mask = instance_labels == id\n",
    "        z = np.asarray(file.z[mask])\n",
    "        if z.mean() - z.min() > 6.0:\n",
    "            remap[mask] = ehydro_classes['tree']\n",
    "        else:\n",
    "            remap[mask] = ehydro_classes['low_vegetation']\n",
    "\n",
    "    remap = np.where(semantic_labels == 6, ehydro_classes['others'], remap)\n",
    "    file.semantic_pred = remap\n",
    "    file.instance_pred = instance_labels\n",
    "\n",
    "    chunk_size = 50\n",
    "    xy = np.stack([file.x, file.y], axis=1)\n",
    "\n",
    "    min_xy = xy.min(axis=0)\n",
    "    max_xy = xy.max(axis=0)\n",
    "    \n",
    "    chunk_idx = np.floor((xy - min_xy) / chunk_size).astype(int)\n",
    "    chunk_keys, inverse = np.unique(chunk_idx, axis=0, return_inverse=True)\n",
    "    \n",
    "    for j, key in enumerate(chunk_keys):\n",
    "        a_priori_chunks += 1\n",
    "\n",
    "        mask = inverse == j\n",
    "        pts_chunk = file.points[mask]\n",
    "        xy_chunk = xy[mask]\n",
    "        instance_labels_chunk = instance_labels[mask]\n",
    "        semantic_pred_chunk = remap[mask]\n",
    "\n",
    "        min_chunk = xy_chunk.min(axis=0)\n",
    "        max_chunk = xy_chunk.max(axis=0)\n",
    "        span = max_chunk - min_chunk\n",
    "        \n",
    "        if np.all(span < 0.8 * chunk_size):\n",
    "            continue\n",
    "\n",
    "        complete_chunks += 1\n",
    "        uniq = np.unique(instance_labels_chunk)\n",
    "        if len(uniq) < 5 or len(np.unique(semantic_pred_chunk)) < 3:\n",
    "            continue\n",
    "\n",
    "        valid_chunks += 1\n",
    "        instance_labels_chunk = uniq.searchsorted(instance_labels_chunk)\n",
    "\n",
    "        out = laspy.create(point_format=file.point_format, file_version=file.header.version)\n",
    "        out.header.scales = file.header.scales\n",
    "        out.header.offsets = file.header.offsets\n",
    "\n",
    "        out.points = pts_chunk\n",
    "        out.instance_pred = instance_labels_chunk\n",
    "        out.write(ehydro_folder[1] / f'plot_ehydro_{i}_{j}.las')\n",
    "\n",
    "    file.write(ehydro_folder[2] / f'plot_ehydro_{i}.las')\n",
    "\n",
    "print(f'Chunks a priori: {a_priori_chunks}')\n",
    "print(f'Chunks completos, con al menos un 80% del tamaño requerido: {complete_chunks} ({((complete_chunks / a_priori_chunks) * 100):.2f}%)')\n",
    "print(f'Chunks válidos, con al menos tres instancias y tres clases presentes: {valid_chunks} ({((valid_chunks / a_priori_chunks) * 100):.2f}%)')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
