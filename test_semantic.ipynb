{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchsparse\n",
    "import laspy\n",
    "\n",
    "from EHydro_TreeUnet.tree_projector import TreeProjector\n",
    "from EHydro_TreeUnet.tree_unet import UNet\n",
    "from pathlib import Path\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as tF\n",
    "from torch.cuda import amp\n",
    "from torchsparse import SparseTensor\n",
    "from torchsparse.nn import functional as F\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchsparse.utils.collate import sparse_collate_fn\n",
    "from torchsparse.utils.quantize import sparse_quantize\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING = True\n",
    "\n",
    "CHANNELS = [64, 128, 256]\n",
    "LATENT_DIM = 512\n",
    "MAX_INSTANCES = 64\n",
    "TRAIN_PCT = 0.8\n",
    "VOXEL_SIZE = 0.2\n",
    "DATA_AUGMENTATION_COEF = 1.0\n",
    "SEMANTIC_LOSS_COEF = 1.0\n",
    "INSTANCE_LOSS_COEF = 0.0\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FORinstanceDataset:\n",
    "    def __init__(self, voxel_size: float, data_augmentation: float = 1.0, yaw_range = (0, 360), tilt_range = (-5, 5), scale = (0.9, 1.1)) -> None:\n",
    "        self._rng = np.random.default_rng()\n",
    "        self._folder = Path('./datasets/MixedDataset')\n",
    "        self._extensions = ('.laz', '.las')\n",
    "        self._feat_channels = 1\n",
    "        self._num_classes = 3\n",
    "        self._class_names = ['Terrain', 'Stem', 'Live-branches']\n",
    "        self._class_labels = np.array([1, 4, 5])  # IDs en el dataset original. Se remapean a [0, 1, 2]\n",
    "        self._class_colormap = np.array([\n",
    "            [128, 128, 128],# clase 0 - Terrain - gris\n",
    "            [255, 165, 0],  # clase 1 - Stem - naranja\n",
    "            [0, 128, 0],    # clase 2 - Live-branches - verde oscuro\n",
    "        ], dtype=np.uint8)\n",
    "        \n",
    "        self._files = sorted(\n",
    "            [f for f in self._folder.rglob(\"*\") if f.is_file() and f.suffix.lower() in self._extensions],\n",
    "            key=lambda f: f.name\n",
    "        )\n",
    "\n",
    "        self._voxel_size = voxel_size\n",
    "        self._len = int(len(self._files) * data_augmentation)\n",
    "        \n",
    "        self._yaw_range = yaw_range\n",
    "        self._tilt_range = tilt_range\n",
    "        self._scale = scale\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, slice):\n",
    "            return [self._preprocess(self.files[i]) for i in range(*idx.indices(len(self)))]\n",
    "        elif isinstance(idx, int):\n",
    "            if idx < 0:\n",
    "                idx += len(self)\n",
    "            if idx < 0 or idx >= len(self):\n",
    "                raise IndexError(\"Index out of range\")\n",
    "            return self._preprocess(idx)\n",
    "        else:\n",
    "            raise TypeError(\"Index must be a slice or an integer\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    @property\n",
    "    def feat_channels(self):\n",
    "        return self._feat_channels\n",
    "    \n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return self._num_classes\n",
    "\n",
    "    @property\n",
    "    def class_names(self):\n",
    "        return self._class_names\n",
    "    \n",
    "    @property\n",
    "    def class_colormap(self):\n",
    "        return self._class_colormap\n",
    "    \n",
    "    def _load_file(self, path):\n",
    "        ext = path.suffix.lower()\n",
    "\n",
    "        coords = ...\n",
    "        feats = ...\n",
    "        semantic_labels = ...\n",
    "        \n",
    "        if ext in ('.las, .laz'):\n",
    "            file = laspy.read(path)\n",
    "\n",
    "            coords = np.vstack((file.x, file.y, file.z)).transpose()\n",
    "            coords -= np.min(coords, axis=0, keepdims=True)\n",
    "            # feats = np.hstack((np.array(file.intensity)[:, None], coords))\n",
    "            feats = np.array(file.intensity)[:, None] / 65535\n",
    "            semantic_labels = np.array(file.classification)\n",
    "            instance_labels = np.array(file.treeID)\n",
    "        else:\n",
    "            raise ValueError(f'Unsopported file extension: {ext}!')\n",
    "\n",
    "        return coords, feats, semantic_labels, instance_labels\n",
    "    \n",
    "    def _agument_data(self, coords):\n",
    "        yaw = np.deg2rad(self._rng.uniform(*self._yaw_range))\n",
    "        pitch = np.deg2rad(self._rng.uniform(*self._tilt_range))\n",
    "        roll = np.deg2rad(self._rng.uniform(*self._tilt_range))\n",
    "        scale = self._rng.uniform(*self._scale)\n",
    "\n",
    "        cy, sy = np.cos(yaw), np.sin(yaw)\n",
    "        cp, sp = np.cos(pitch), np.sin(pitch)\n",
    "        cr, sr = np.cos(roll), np.sin(roll)\n",
    "\n",
    "        rotation_mtx = np.array([[cy*cp,  cy*sp*sr - sy*cr,  cy*sp*cr + sy*sr],\n",
    "                                 [sy*cp,  sy*sp*sr + cy*cr,  sy*sp*cr - cy*sr],\n",
    "                                 [ -sp ,            cp*sr ,            cp*cr ]],\n",
    "                                dtype=coords.dtype)\n",
    "\n",
    "        return (coords @ rotation_mtx.T) * scale\n",
    "        \n",
    "    def _preprocess(self, idx: int):\n",
    "        coords, feat, semantic_labels, instance_labels = self._load_file(self._files[idx % len(self._files)])\n",
    "        if idx >= len(self._files):\n",
    "            coords = self._agument_data(coords)\n",
    "\n",
    "        voxels, indices, inverse_map = sparse_quantize(coords, self._voxel_size, return_index=True, return_inverse=True)\n",
    "        feat = feat[indices]\n",
    "        semantic_labels = semantic_labels[indices]\n",
    "        instance_labels = instance_labels[indices]\n",
    "\n",
    "        voxels = torch.tensor(voxels, dtype=torch.int)\n",
    "        feat = torch.tensor(feat.astype(np.float32), dtype=torch.float)\n",
    "        semantic_labels = torch.tensor(semantic_labels, dtype=torch.long)\n",
    "        instance_labels = torch.tensor(instance_labels, dtype=torch.long)\n",
    "\n",
    "        inputs = SparseTensor(coords=voxels, feats=feat)\n",
    "        semantic_labels = SparseTensor(coords=voxels, feats=semantic_labels)\n",
    "        instance_labels = SparseTensor(coords=voxels, feats=instance_labels)\n",
    "\n",
    "        return {\"inputs\": inputs, \"semantic_labels\": semantic_labels, \"instance_labels\": instance_labels, \"coords\": coords, \"inverse_map\": inverse_map}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeProjectorTrainer:\n",
    "    def __init__(self):\n",
    "        conv_config = F.conv_config.get_default_conv_config(conv_mode=F.get_conv_mode())\n",
    "        conv_config.kmap_mode = 'hashmap'\n",
    "        F.conv_config.set_global_conv_config(conv_config)\n",
    "\n",
    "        self._dataset = FORinstanceDataset(voxel_size=VOXEL_SIZE, data_augmentation=DATA_AUGMENTATION_COEF)\n",
    "        train_size = int(TRAIN_PCT * len(self._dataset))\n",
    "        val_size = len(self._dataset) - train_size\n",
    "\n",
    "        self._model = TreeProjector(self._dataset.feat_channels, self._dataset.num_classes, MAX_INSTANCES, channels = CHANNELS, latent_dim = LATENT_DIM)\n",
    "        # self._model = UNet(self._dataset.feat_channels, self._dataset.num_classes, base_channels=64, depth=3)\n",
    "        self._device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        total_params = sum(p.numel() for p in self._model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self._model.parameters() if p.requires_grad)\n",
    "\n",
    "        print(f\"Parámetros totales: {total_params:,}\")\n",
    "        print(f\"Parámetros entrenables: {trainable_params:,}\")\n",
    "        \n",
    "        train_dataset, val_dataset = random_split(self._dataset, [train_size, val_size])\n",
    "\n",
    "        self._train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=sparse_collate_fn)\n",
    "        self._val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=sparse_collate_fn)\n",
    "\n",
    "        self._criterion_semantic = nn.CrossEntropyLoss()\n",
    "        self._criterion_instance = nn.CrossEntropyLoss()\n",
    "\n",
    "        if not TRAINING:\n",
    "            self._load_weights()\n",
    "\n",
    "        self._model.to(self._device)\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        return self._dataset\n",
    "\n",
    "    def _load_weights(self):\n",
    "        self._model.load_state_dict(torch.load('./weights/tree_unet_weights.pth'))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _apply_hungarian(self, logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "        return labels\n",
    "        N, K = logits.shape\n",
    "        device = logits.device\n",
    "\n",
    "        log_p = tF.log_softmax(logits, dim=-1)\n",
    "\n",
    "        uniq = torch.unique(labels)\n",
    "        M    = len(uniq)\n",
    "\n",
    "        cost = torch.empty((M, K), device=device)\n",
    "        for m, g in enumerate(uniq):\n",
    "            mask = (labels == g)\n",
    "            cost[m] = -(log_p[mask].mean(0))\n",
    "\n",
    "        row, col = linear_sum_assignment(cost.detach().cpu())\n",
    "\n",
    "        remapped = torch.full_like(labels, fill_value=-1)\n",
    "        for r, c in zip(row, col):\n",
    "            g = uniq[r]\n",
    "            remapped[labels == g] = c\n",
    "\n",
    "        return remapped\n",
    "\n",
    "    def _compute_loss(self, semantic_output, semantic_labels, instance_output = 0, instance_labels = 0):\n",
    "        loss_sem = self._criterion_semantic(semantic_output, semantic_labels)\n",
    "        # loss_inst = self._criterion_instance(instance_output, self._apply_hungarian(instance_output, instance_labels))\n",
    "        loss_inst = 0\n",
    "\n",
    "        return SEMANTIC_LOSS_COEF * loss_sem + INSTANCE_LOSS_COEF * loss_inst\n",
    "    \n",
    "    def _compute_iou(self, semantic_output, semantic_labels):\n",
    "        if semantic_output.C.shape != semantic_labels.C.shape or not torch.all(semantic_output.C == semantic_labels.C):\n",
    "            raise ValueError(\"Dimensions doesn't match between semantic labels and output.\")\n",
    "\n",
    "        semantic_output = semantic_output.F.argmax(dim=1)\n",
    "        semantic_labels = semantic_labels.F.view(-1).long()\n",
    "        iou_list = torch.full((self._dataset.num_classes,), float('nan'), device=semantic_output.device)\n",
    "\n",
    "        for cls in range(self._dataset.num_classes):\n",
    "            label_mask = semantic_labels == cls\n",
    "            out_mask = semantic_output == cls\n",
    "\n",
    "            union = (out_mask | label_mask).sum()\n",
    "            if union == 0:\n",
    "                continue\n",
    "\n",
    "            inter = (out_mask & label_mask).sum()\n",
    "            iou_list[cls] = inter.float() / union.float()\n",
    "\n",
    "        valid = ~torch.isnan(iou_list)\n",
    "        miou  = iou_list[valid].mean().item() if valid.any() else float(\"nan\")\n",
    "        return iou_list, miou\n",
    "            \n",
    "    def _gen_charts(self, losses, iou_list, miou, training):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(losses, label=f\"{'Training' if training else 'Inference'} Loss\")\n",
    "        plt.xlabel(\"Step\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(f\"Loss evolution during {'Training' if training else 'Inference'}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(miou, label=f\"{'Training' if training else 'Inference'} mIoU\")\n",
    "        plt.xlabel(\"Step\")\n",
    "        plt.ylabel(\"mIoU\")\n",
    "        plt.title(f\"mIoU evolution during {'Training' if training else 'Inference'}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        iou_arr = np.asarray(iou_list)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        for c in range(self._dataset.num_classes):\n",
    "            plt.plot(iou_arr[:, c], label=self._dataset.class_names[c])\n",
    "        \n",
    "        plt.xlabel(\"Step\")\n",
    "        plt.ylabel(\"IoU\")\n",
    "        plt.title(f\"IoU evolution during {'Training' if training else 'Inference'}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    def train(self):\n",
    "        optimizer = torch.optim.Adam(self._model.parameters(), lr=1e-3)\n",
    "        scaler = amp.GradScaler(enabled=True)\n",
    "        losses = []\n",
    "        iou_list = []\n",
    "        miou = []\n",
    "\n",
    "        for k, feed_dict in enumerate(self._train_loader):\n",
    "            inputs = feed_dict[\"inputs\"].to(self._device)\n",
    "            semantic_labels = feed_dict[\"semantic_labels\"].to(self._device)\n",
    "            instance_labels = feed_dict[\"instance_labels\"].to(self._device)\n",
    "\n",
    "            with amp.autocast(enabled=True):\n",
    "                # semantic_output, instance_output = self._model(inputs)\n",
    "                semantic_output = self._model(inputs)\n",
    "                # loss = self._compute_loss(semantic_output.F, semantic_labels.F, instance_output.F, instance_labels.F)\n",
    "                loss = self._compute_loss(semantic_output.F, semantic_labels.F)\n",
    "                step_iou, step_miou = self._compute_iou(semantic_output, semantic_labels)\n",
    "                iou_list.append(step_iou.cpu().numpy())\n",
    "                miou.append(step_miou)\n",
    "\n",
    "            print(f\"[Train step {k + 1}] loss = {loss.item()}; mIoU = {step_miou}\")\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        torch.save(self._model.state_dict(), './weights/tree_unet_weights.pth')\n",
    "        self._gen_charts(losses, iou_list, miou, True)\n",
    "\n",
    "    def eval(self):\n",
    "        self._model.eval()\n",
    "        losses = []\n",
    "        iou_list = []\n",
    "        miou = []\n",
    "\n",
    "        # enable torchsparse 2.0 inference\n",
    "        # enable fused and locality-aware memory access optimization\n",
    "        torchsparse.backends.benchmark = True  # type: ignore\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for k, feed_dict in enumerate(self._val_loader):\n",
    "                semantic_labels_cpu = feed_dict[\"semantic_labels\"].F.numpy()\n",
    "                instance_labels_cpu = feed_dict[\"instance_labels\"].F.numpy()\n",
    "                coords = feed_dict[\"coords\"].numpy()\n",
    "                inverse_map = feed_dict[\"inverse_map\"].numpy()\n",
    "\n",
    "                inputs = feed_dict[\"inputs\"].to(self._device)\n",
    "                semantic_labels = feed_dict[\"semantic_labels\"].to(self._device)\n",
    "                instance_labels = feed_dict[\"instance_labels\"].to(self._device)\n",
    "\n",
    "                with amp.autocast(enabled=True):\n",
    "                    # semantic_output, instance_output = self._model(inputs)\n",
    "                    semantic_output = self._model(inputs)\n",
    "                    # loss = self._compute_loss(semantic_output.F, semantic_labels.F, instance_output.F, instance_labels.F)\n",
    "                    loss = self._compute_loss(semantic_output.F, semantic_labels.F)\n",
    "                    step_iou, step_miou = self._compute_iou(semantic_output, semantic_labels)\n",
    "                    iou_list.append(step_iou.cpu().numpy())\n",
    "                    miou.append(step_miou)\n",
    "\n",
    "                print(f\"[Inference step {k + 1}] loss = {loss.item()}; mIoU = {step_miou}\")\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                voxels = semantic_output.C[:, 1:].cpu().numpy()\n",
    "                semantic_output = torch.argmax(semantic_output.F.cpu(), dim=1).numpy()\n",
    "                # instance_output = torch.argmax(instance_output.F.cpu(), dim=1).numpy()\n",
    "                instance_output = np.zeros(semantic_output.shape)\n",
    "\n",
    "                yield voxels, semantic_output, instance_output, semantic_labels_cpu, instance_labels_cpu, coords, inverse_map\n",
    "\n",
    "        self._gen_charts(losses, iou_list, miou, False)\n",
    "\n",
    "        print(f'Loss medio: {sum(losses) / len(losses)}')\n",
    "        print(f'mIoU medio: {sum(miou) / len(miou)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntester = TreeProjectorTrainer()\\n\\ntorch.manual_seed(0)\\n\\nN, K = 12, 3                       # 12 puntos, 3 canales (max_inst)\\nsemantic_lbl = torch.randint(0, 4, (N,))\\n\\n# Instancias GT: bloques de 4 puntos\\ninst_lbl = torch.tensor([0]*4 + [1]*4 + [2]*4)\\n\\n# Logits: cada instancia favorece un canal *distinto*\\ninst_out = torch.randn(N, K) * 0.3\\ninst_out[:4, 1] += 3.0   # inst-0 -> canal-1\\ninst_out[4:8, 2] += 3.0  # inst-1 -> canal-2\\ninst_out[8:, 0]  += 3.0  # inst-2 -> canal-0\\n\\n# Pérdida con labels originales (mala correspondencia)\\nloss_bad = tester._criterion_instance(inst_out, inst_lbl)\\n\\n# Pérdida tras húngaro + remapeo\\nremap = tester._apply_hungarian(inst_out, inst_lbl)\\nprint(remap)\\nloss_good = tester._criterion_instance(inst_out, remap)\\n\\nprint(f\"Loss antes  = {loss_bad.item():.3f}\")\\nprint(f\"Loss después = {loss_good.item():.3f}\")\\n\\nprint(inst_out)\\nprint(inst_lbl)\\nprint(remap)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tester = TreeProjectorTrainer()\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "N, K = 12, 3                       # 12 puntos, 3 canales (max_inst)\n",
    "semantic_lbl = torch.randint(0, 4, (N,))\n",
    "\n",
    "# Instancias GT: bloques de 4 puntos\n",
    "inst_lbl = torch.tensor([0]*4 + [1]*4 + [2]*4)\n",
    "\n",
    "# Logits: cada instancia favorece un canal *distinto*\n",
    "inst_out = torch.randn(N, K) * 0.3\n",
    "inst_out[:4, 1] += 3.0   # inst-0 -> canal-1\n",
    "inst_out[4:8, 2] += 3.0  # inst-1 -> canal-2\n",
    "inst_out[8:, 0]  += 3.0  # inst-2 -> canal-0\n",
    "\n",
    "# Pérdida con labels originales (mala correspondencia)\n",
    "loss_bad = tester._criterion_instance(inst_out, inst_lbl)\n",
    "\n",
    "# Pérdida tras húngaro + remapeo\n",
    "remap = tester._apply_hungarian(inst_out, inst_lbl)\n",
    "print(remap)\n",
    "loss_good = tester._criterion_instance(inst_out, remap)\n",
    "\n",
    "print(f\"Loss antes  = {loss_bad.item():.3f}\")\n",
    "print(f\"Loss después = {loss_good.item():.3f}\")\n",
    "\n",
    "print(inst_out)\n",
    "print(inst_lbl)\n",
    "print(remap)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros totales: 20,721,088\n",
      "Parámetros entrenables: 20,721,088\n",
      "[Train step 1] loss = 1.128998041152954; mIoU = 0.13685661554336548\n",
      "[Train step 2] loss = 1.7908799648284912; mIoU = 0.3782099485397339\n",
      "[Train step 3] loss = 0.9463444352149963; mIoU = 0.3891075551509857\n",
      "[Train step 4] loss = 0.8335906863212585; mIoU = 0.3812865614891052\n",
      "[Train step 5] loss = 0.4928686022758484; mIoU = 0.6102868914604187\n",
      "[Train step 6] loss = 0.7296002507209778; mIoU = 0.32844945788383484\n",
      "[Train step 7] loss = 0.7279515862464905; mIoU = 0.35073721408843994\n",
      "[Train step 8] loss = 0.4515005648136139; mIoU = 0.5408915281295776\n",
      "[Train step 9] loss = 0.3928975760936737; mIoU = 0.5312796831130981\n",
      "[Train step 10] loss = 0.3937716484069824; mIoU = 0.5829260349273682\n",
      "[Train step 11] loss = 0.37912169098854065; mIoU = 0.575190544128418\n",
      "[Train step 12] loss = 0.29264360666275024; mIoU = 0.5915581583976746\n",
      "[Train step 13] loss = 0.419923335313797; mIoU = 0.5772384405136108\n",
      "[Train step 14] loss = 0.3521971106529236; mIoU = 0.5492689609527588\n",
      "[Train step 15] loss = 0.3476080298423767; mIoU = 0.59388267993927\n",
      "[Train step 16] loss = 0.33398476243019104; mIoU = 0.6183929443359375\n",
      "[Train step 17] loss = 0.37738919258117676; mIoU = 0.6324213743209839\n",
      "[Train step 18] loss = 0.6065167188644409; mIoU = 0.30244022607803345\n",
      "[Train step 19] loss = 0.3604162931442261; mIoU = 0.650559663772583\n",
      "[Train step 20] loss = 0.3605167269706726; mIoU = 0.618098258972168\n",
      "[Train step 21] loss = 0.366362065076828; mIoU = 0.5577776432037354\n",
      "[Train step 22] loss = 0.35353657603263855; mIoU = 0.6379865407943726\n",
      "[Train step 23] loss = 0.2988833785057068; mIoU = 0.5875341296195984\n",
      "[Train step 24] loss = 0.28520873188972473; mIoU = 0.5974463820457458\n",
      "[Train step 25] loss = 0.28963521122932434; mIoU = 0.6327738165855408\n",
      "[Train step 26] loss = 0.29552578926086426; mIoU = 0.5916033983230591\n",
      "[Train step 27] loss = 0.6185019016265869; mIoU = 0.5101048946380615\n",
      "[Train step 28] loss = 0.35782763361930847; mIoU = 0.60539311170578\n",
      "[Train step 29] loss = 0.23141708970069885; mIoU = 0.6926053762435913\n",
      "[Train step 30] loss = 0.2563253939151764; mIoU = 0.6182020306587219\n",
      "[Train step 31] loss = 0.27183282375335693; mIoU = 0.6898066997528076\n",
      "[Train step 32] loss = 0.2681978642940521; mIoU = 0.6671316027641296\n",
      "[Train step 33] loss = 0.24870039522647858; mIoU = 0.6497715711593628\n",
      "[Train step 34] loss = 0.3396860659122467; mIoU = 0.6310825347900391\n",
      "[Train step 35] loss = 0.34634262323379517; mIoU = 0.5995545387268066\n",
      "[Train step 36] loss = 0.21516768634319305; mIoU = 0.6663658022880554\n",
      "[Train step 37] loss = 0.29074642062187195; mIoU = 0.6405328512191772\n",
      "[Train step 38] loss = 0.3286946713924408; mIoU = 0.6558310985565186\n",
      "[Train step 39] loss = 0.18209268152713776; mIoU = 0.6953220367431641\n",
      "[Train step 40] loss = 0.2954975664615631; mIoU = 0.634086012840271\n",
      "[Train step 41] loss = 0.6427395939826965; mIoU = 0.3789735734462738\n",
      "[Train step 42] loss = 0.4985700845718384; mIoU = 0.46099215745925903\n",
      "[Train step 43] loss = 0.23372773826122284; mIoU = 0.6714078783988953\n",
      "[Train step 44] loss = 0.2789090573787689; mIoU = 0.6606915593147278\n",
      "[Train step 45] loss = 0.21542595326900482; mIoU = 0.7614970207214355\n",
      "[Train step 46] loss = 0.2898416817188263; mIoU = 0.6598394513130188\n",
      "[Train step 47] loss = 2.382261037826538; mIoU = 0.2679806351661682\n",
      "[Train step 48] loss = 0.21011599898338318; mIoU = 0.7224639654159546\n",
      "[Train step 49] loss = 0.18494677543640137; mIoU = 0.8275173902511597\n",
      "[Train step 50] loss = 0.5006521940231323; mIoU = 0.6859525442123413\n",
      "[Train step 51] loss = 0.30829402804374695; mIoU = 0.6165827512741089\n",
      "[Train step 52] loss = 0.20644067227840424; mIoU = 0.7031189799308777\n",
      "[Train step 53] loss = 0.2732308804988861; mIoU = 0.6990303993225098\n",
      "[Train step 54] loss = 0.34060871601104736; mIoU = 0.6871821284294128\n",
      "[Train step 55] loss = 0.3563176989555359; mIoU = 0.6132357716560364\n",
      "[Train step 56] loss = 0.28789129853248596; mIoU = 0.6868724822998047\n",
      "[Train step 57] loss = 1.9493286609649658; mIoU = 0.46502551436424255\n",
      "[Train step 58] loss = 0.36098966002464294; mIoU = 0.675330400466919\n",
      "[Train step 59] loss = 0.26446855068206787; mIoU = 0.6888704299926758\n",
      "[Train step 60] loss = 0.33214271068573; mIoU = 0.6388766765594482\n",
      "[Train step 61] loss = 0.20137640833854675; mIoU = 0.8084623217582703\n",
      "[Train step 62] loss = 0.44995540380477905; mIoU = 0.5740900635719299\n",
      "[Train step 63] loss = 0.4795093238353729; mIoU = 0.4051865041255951\n"
     ]
    }
   ],
   "source": [
    "tester = TreeProjectorTrainer()\n",
    "\n",
    "if TRAINING:\n",
    "    tester.train()\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "for voxels, semantic_output, instance_output, semantic_labels, instance_labels, coords, inverse_map in tester.eval():\n",
    "    continue\n",
    "    coords = coords[0]\n",
    "    inverse_map = inverse_map[0]\n",
    "\n",
    "    colors = tester.dataset.class_colormap[semantic_labels[inverse_map]] / 255.0\n",
    "\n",
    "    pcd.points = o3d.utility.Vector3dVector(coords)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "    colors = tester.dataset.class_colormap[semantic_output[inverse_map]] / 255.0\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "    unique_ids = np.unique(instance_labels)\n",
    "    rng = np.random.default_rng(0)\n",
    "    palette = rng.random((len(unique_ids), 3))\n",
    "\n",
    "    id2color = {uid: palette[i] for i, uid in enumerate(unique_ids)}\n",
    "    colors = np.array([id2color[i] for i in instance_labels], dtype=np.float64)\n",
    "\n",
    "    pcd.points = o3d.utility.Vector3dVector(coords)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors[inverse_map])\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "    unique_ids = np.unique(instance_output)\n",
    "    rng = np.random.default_rng(0)\n",
    "    palette = rng.random((len(unique_ids), 3))\n",
    "\n",
    "    id2color = {uid: palette[i] for i, uid in enumerate(unique_ids)}\n",
    "    colors = np.array([id2color[i] for i in instance_output], dtype=np.float64)\n",
    "\n",
    "    pcd.points = o3d.utility.Vector3dVector(coords)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors[inverse_map])\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
